---
title: "Functions for simulating data and designing studies of physiological flexibility in the acute glucocorticoid response to stressors"
author: 
 - Conor C. Taff
header-includes:
  - \usepackage[font={footnotesize}, labelfont={bf}]{caption}
fontsize: 12pt
output: 
  bookdown::word_document2:
      number_sections: FALSE
      toc: FALSE
      extra_dependcies: ["flafter"]
  bookdown::pdf_document2:
      number_sections: FALSE
      toc: FALSE
      extra_dependencies: ["flafter"]
bibliography: references.bib
csl: animal-behaviour.csl
---

```{r setup, include=FALSE, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(ggplot2, here, MASS, MBESS, tidyverse, viridis, gridExtra, rptR, simcoRt, sp)
```

## ABSTRACT

Wild animals often experience unpredictable challenges that demand rapid and flexible responses. The glucocorticoid mediated stress response is one of the major systems that allows vertebrates to rapidly adjust their physiology and behavior. Given it's role in responding to challenges, evolutionary physiologists have focused on the consequences of between-individual and, more recently, within-individual variation in the acute glucocorticoid response. Although sophisticated approaches are available to partition this variation statistically, empirical studies of physiological flexibility are severely limited by the logistical challenges of measuring the same animal multiple times during a single acute response or across multiple instances of acute responses. Empiricists have largely adopted the strategy of standardizing sampling as much as possible to allow for comparison between individuals, but this standardization also makes it very difficult to detect certain types of variation in the functional shape of acute response curves. Data simulation is a powerful approach when empirical data are limited, but has not been adopted to date in studies of physiological flexibility. In this paper, I describe the `simcoRt` package, which includes functions that can generate realistic acute glucocorticoid response data with user specified characteristics. Simulated animals can be sampled continuously through an acute response and across as many separate responses as desired, while varying key parameters (e.g., the degree of correlation between the speed and scope of a response). Using this simulation, I explore several possible scenarios to highlight areas where simulation might either provide new insight into physiological flexibility directly or aid in designing empirical studies that are better able to test the hypotheses of interest. The package includes a vignette with details on use and code to reproduce all of the examples explored in this paper.

## INTRODUCTION

Animals live in a dynamic environment in which they regularly encounter unpredictable challenges. Successfully navigating these challenges often requires the ability to rapidly adjust behavior and physiology to match current conditions. For vertebrates, the glucocorticoid mediated stress response plays a major role in coordinating these changes when stressors are encountered [@wingfield1998; @sapolsky2000] and similar rapid response systems mediate changes in other taxa [@taborsky2020]. Because of the central role that this response plays in coping with challenges, a great deal of research effort over the past 15 years has focused on understanding whether between-individual differences in the magnitude of this response predict coping ability and, ultimately, fitness [@breuner2008; @schoenle2020]. 

More recently, a series of conceptual papers have asked whether the degree of within-individual variation in glucocorticoid modulation (i.e., endocrine flexibility) across different contexts or in response to different stressors might also be an important predictor of performance [@taff2016; @hau2016; @wada2014; @lema2013]. Perhaps the major limit to empirical progress, especially for within-individual variation, is the logistical difficulty of accurately characterizing the functional shape of the acute physiological stress response for an individual during a single acute response and across multiple acute responses occurring under different conditions. Often these measures are strictly limited by the number of samples that can safely be taken from an animal during a single capture and the number of repeated captures that are possible [but see @koolhaas2011]. Given these limitations, data simulation is a powerful tool that could complement empirical work in this area, but that has not yet been applied to studies of endocrine flexibility.

Several recent papers have suggested that physiologists interested in endocrine flexibility should adopt a within-individual reaction norm approach [e.g., @hau2016; @taff2016]. This approach has been widely adopted in studies of behavioral flexibility where statistical methods and empirical progress have developed synergistically [e.g., @araya2015; @dingemanse2010; @westneat2015]. This field has also benefited from simulation studies to evaluate optimal study design [@van2012] and packages that can create artificial datasets with desired patterns of between, within, and residual variance to evaluate the consequences of different patterns of variation on the ability to detect effects [see SQuID package, @allegue2017]. While these approaches are powerful, they have proven difficult to apply directly to endocrine flexibility data for two reasons. First, simulation studies suggest that many patterns may only be detectable with a level of repeated sampling that is possible for many behaviors (especially when collected autonomously), but that is currently not possible for most studies of endocrine flexibility. Second, and more fundamentally, these papers often focus on somewhat discrete measures of behavior (e.g., aggression score or activity level), whereas for acute glucocorticoid responses, the functional shape of the response itself may be the important trait and it may not be possible to summarize variation in the shape of the response with a single measure.

The function valued trait (FVT) framework is an alternative approach that explicitly considers the functional shape of a biological response [@gomulkiewicz2018; @stinchcombe2012; @kingsolver2015]. While FVT approaches have been suggested for studies of endocrine flexibility [@taff2016], I am not aware of any papers that have applied this framework to empirical data on acute glucocorticoid responses, probably because sufficient data are not available. Conceptually, however, this approach is a better match to the acute glucocorticoid response, because the shape of a response curve is explicitly considered as the phenotypic trait of interest. In some cases, it may make sense to estimate particular parameters of the curve (e.g., maximum rate of increase and maximum value reached) and then treat those parameters as phenotypic values for downstream analysis, although statistical methods also exist to analyze the shape of the entire curve directly without the need to extract discrete parameters [@kingsolver2015]. This approach has been used to study a variety of phenotypes where values can be measured continuously or pooled across many individuals from the same group to accurately estimate the shape of a curve [see Table 1 in @stinchcombe2012]. Applying the technique to endocrine flexibility at the within-individual level faces the same empirical challenges described for within-individual reaction norms above. Note that FVT and within-individual reaction norms approaches are not necessarily incompatible, but they have largely developed separately.

The recognition that characterizing the functional shape of an acute stress response is challenging goes back to the earliest studies conducted in wild animals. Early studies often employed various control groups and sampled individual animals at a variety of time points over a long period in order to describe the full response curve for a particular group [e.g., a species or a breeding stage, @wingfield1992]. These validations were considered essential to characterize key parameters of the acute response for each group being studied (i.e., baseline, rate of increase, maximum level, time of peak, and area under the curve; John Wingfield, personal communication). The challenge of estimating these parameters becomes much more difficult when trying to describe the response for an individual animal rather than for a group, because glucocorticoids can often only be measured at two or three time points and only a small number of times per animal [e.g., @vitousek2018]. Because these studies require an estimate for each individual, the solutions used by older studies that added additional animals to allow for sampling at more time points are not available.

For individual based studies, the most common approach to this problem is to standardize measurements as much as possible by measuring animals at the same time of the day during the same context, and by taking blood samples at standard times (often <3 and 30 minutes after capture) to characterize baseline and stress-induced glucocorticoids. This standardization allows for comparison between individuals, but in some cases it may also completely obscure the ability to detect variation in certain characteristics of the acute response curve. For example, if the speed (rate of initial increase) and scope (maximum value) of the acute response vary independently, samples taken at only two time points cannot accurately capture variation in either parameter. Indeed, several discussions in recent years about methods such as the '3 minute rule' and the relative merits of 'area under the curve' versus time point measures of glucocorticoids are fundamentally related to a recognition of the importance of understanding variation in the functional shape of stress responses and whether different components of that shape covary within individuals [e.g., @cockrem2002; @small2017].

One of the characteristics of both the within-individual reaction norm and FVT literature is that empirical work has proceeded in very close coordination with simulation and statistical method development. In contrast, studies of endocrine flexibility often point to these methods, but don't address the ways that the particular logistical challenges of hormone measurement might suggest altered study designs. While many of the tools developed in these fields are transferable, studies of physiological flexibility would benefit from a focus on analysis development and testing that explicitly incorporates the particular details of these questions. One way to accomplish these goals is to use simulations, but to my knowledge no studies of physiological flexibility have developed simulations of the acute stress response that address the issues discussed above.

Data simulation is a powerful approach for several reasons. Because true parameter values (e.g., maximum glucocorticoid level) are known, it is possible to evaluate how well different study designs and analytical choices perform in recovering true patterns and how sensitive those designs are to different assumptions. Thus, simulation can tell us whether the study designs we use can *in principle* detect the patterns we predict given realistic effect sizes. Simulated data can also identify conditions under which current study designs will perform well or poorly. For example, if simulations suggest that the baseline paired with stress-induced paradigm only works well when the speed and scope of responses are positively correlated, then empirical work could seek to determine the degree of correlation for a particular study system as justification for the approach. This ability to highlight key assumptions and create data sets with known properties has the potential to both provide insight into physiological flexibility directly and to guide empirical work by improving study design and identifying key areas for subsequent sampling. In the rest of this paper, I develop a simple simulation of acute physiological stress responses and then briefly illustrate several possible applications of the simulation. 

## DESCRIPTION OF THE SIMULATION

I developed a package called `simcoRt` in R version 4.0.2 [@rcore] with functions to generate acute physiological response curves. This simulation makes no assumptions about the  mechanistic process that results in the shape of a glucocorticoid response. Rather, parameters are sampled to generate curves that are similar in shape and degree of variation to empirically observed responses (Figure \@ref(fig:concept-fig)). This simulation is designed to create data sets with realistic structure that can be used to better design and plan studies of physiological flexibility, to evaluate power of current study designs, and to evaluate the sensitivity of sampling regimes to any number of modifications to the shape of glucocorticoid response curves (e.g., changing covariation patterns between different features of the response). I explore a small number of scenarios in the next section, but I expect that many other scenarios can be addressed with these tools. For illustration purposes, I refer to simulated glucocorticoid responses, but the simulation applies equally well to any physiological mediator of a rapid response. The package can be installed in R using the following command.

```{r simp-ackage, message = FALSE, warning = FALSE}
devtools::install_github("cct663/simcoRt")
```

```{r concept-fig, echo = FALSE, message = FALSE, warning = FALSE, out.width = '90%', fig.cap = "Conceptual illustration of the structure of the simulation. For each simulated animal, seven parameters are sampled from a multivariate normal distribution. Together, these seven parameters define the turning points in an acute response curve. The mean and standard deviation for each parameter can be set along with the degree of covariation between each pair of parameters. Note that the simulation can easily be simplified as desired by setting some parameter mean or standard deviations to zero."}
knitr::opts_chunk$set(fig.pos = "!H")

knitr::include_graphics("concept.png")


```
     
The simulation is constructed as two main functions with several minor functions for downstream analysis. Detailed descriptions of the arguments to each function and a full vignette are included with the package documentation. Briefly, function `cort_sim1` samples the parameters shown in Figure \@ref(fig:concept-fig) from an arbitrary number of animals. These parameters are sampled from a multivariate normal distribution with user specified mean, variance, and covariance for each parameter. I consider these values to be the 'true', unobserved, phenotype of the animal (setting aside the question of whether or not a 'true' physiological phenotype exists). 

A second function, `cort_sim2`, starts with a population of animals generated from `cort_sim1` and samples observed acute glucocorticoid responses an arbitrary number of times for each animal. Two sources of variation in the observed relative to true parameter values can be specified. First, within-individual variation in expression is represented by specifying what amount of variation in the observation of each parameter is determined by the true value and what amount is determined by an additional randomly sampled response, based on the population parameters (this additional sampling maintains the user specified covariance structure of the population). After sampling the parameters, values are interpolated for each one minute time point and a localized regression is fit to create a smoothed curve that represents the observed glucocorticoid response. From this expressed response, individual data points are then collected at user specified times that would reflect an empirical study design (e.g., 2, 30, and 60 minutes). Additional noise is added to these data points to represent measurement error (e.g., assay error).

The function also generates a simulated performance (e.g., fitness) measure, based on the underlying true values. Data reflecting the true phenotypic values, the repeated expression of acute responses, and the observed time points can then be used in downstream analyses with any standard statistical approaches or software. For example, a user could perform an analysis to ask whether a known relationship between fitness and a particular true parameter is recovered in a study that includes only measures taken at particular time points. An additional convenience function summarizes the output of a simulation run in a multi-panel plot (Figure \@ref(fig:initial-demo)). 

```{r initial-demo, results = FALSE, echo = FALSE, warning = FALSE, message = FALSE, fig.width = 10.2, fig.height = 7.5, fig.cap = "Example of simulation output with default settings. Panel A shows the downsampled data set for this run with samples collected at 1, 15, and 30 minutes in this case. Panel B shows the full observed response curve for each animal. Panel C shows the rank order of glucocorticoid level at each time point for each animal. In each panel, the vertical dashed lines represent the three time points that might have been measured in a typical empirical study. Note that individuals in the top panels do not match perfectly because measurement error is added to the downsampled dataset in panel A."}
  # Make plot with default settings from package 
     set.seed(100)   # makes it reproducible by using same random seed
      demo <- cort_sim2()
      p <- plot_cort_sim(demo)
      p
```

Finally, given recent interest in estimating the repeatability of glucocorticoid regulation [@taff2018; @cockrem2013; @hau2016], I also included a function that takes input from `cort_sim2` and calculates the observed repeatability of several measures using package `rptR` [@stoffel2017]. Full details are included in the package documentation, but this function returns repeatability for each individual time point specified in the down sampled data set, profile repeatability [@reed2019], and repeatability for area under the curve calculated as both increase (AUC~I~) and ground (AUC~G~) approaches [@pruessner2003]. For each AUC measure, the function returns repeatability for the full time course, for an estimate using only the observed values in the down sampled data set, and for the full data set constrained to the time period encompassing the observed data points. Simple plots illustrating repeated samples from the same individuals are also returned by default.

## EXAMPLE APPLICATIONS OF SIMULATION

The goal of this simulation is to provide a flexible tool that can produce realistic datasets of physiological flexibility for a variety of different systems and scenarios. As such, there are many possible applications and here I briefly highlight a few possibilities. These are by no means exhaustive, and I hope the simulation will be a useful tool to guide empirical work for specific hypotheses and study systems. Within each scenario, I have illustrated how the simulation functions might be used to address the particular question of interest, but I have not fully explored all the possible permutations of parameters systematically, because these will depend to a large extent on the empirical details of the system being studied.

### *Simulating empirically parameterized data*

In order for simulation to be useful, we should be able to create artificial datasets that have similar characteristics to empirical data for different systems. Simulating realistic data provides a starting point for evaluating different study designs and the consequences of changes in different assumptions or parameters. Simulating realistic data is also useful because it can aid in study design or be used as a basis for pre-registered reports that demonstrate the feasibility of a planned study before data are ever collected. Simulated data can be created and entered in a complete analysis pipeline, with empirical data substituted later. In addition to helping to design better studies, this approach has the advantage of increasing the transparency and reliability for studies of physiological flexibility, by making analysis choices and predictions clear before data are collected.

Here, I compare simulated data to an empirical dataset from red-winged blackbirds (*Agelaius phoeniceus*) to demonstrate how `simcoRt` can create synthetic datasets similar to observed data. This dataset is included in the `simcoRt` package and is fully described in the documentation. Briefly, acute glucocorticoid responses were measured using a 7-point sampling scheme, with corticosterone measured at 1, 3, 7, 15, 30, 45, and 60 minutes post capture. I simulated data using the functions described above starting with the input values calculated directly from the empirical data. The simulation creates a new dataset that has similar variation and patterns to empirical data (Figure \@ref(fig:rwbb-demo)A) along with a population wide corticosterone response curve shape that closely matches the empirical data (Figure \@ref(fig:rwbb-demo)B). In this case, the plotted simulation data include the same number of animals sampled at the same time points as the empirical data, but these sampling points and total sample size can easily be changed as desired. The parameterized simulation can now be used to test the sensitivity of any number of experimental designs before additional data is collected.

```{r rwbb-demo, echo = FALSE, fig.height = 3.5, fig.width = 8, message = FALSE, warning = FALSE, fig.cap = "Panel A shows the acute corticosterone response for measured (blue) or simulated (orange) red-winged blackbirds measured at seven time points. Panel B shows the mean and standard error of the two datasets."}
      rwde <- subset(rwbb, rwbb$lh_stg == "early-breeding")  
      rwde <- subset(rwde, rwde$id != "452")   # This one has an unusually high cort response
    set.seed(165)
        sim_rwd <- cort_sim2(cort_sim1(
       n = 23,
       base_mu = 3.5,
       base_sd = 3.5,
       slope_mu = 17,
       slope_sd = 0.7,
       fastpct_mu = 0.7,
       fastpct_sd = 0.03,
       max_mu = log(56),
       max_sd = 0.5,
       speed_mu = 65,
       speed_sd = 5,
       return_mu = 120,
       maxtime_mu = 25,
       cor_max_slope = -0.7
     ), 
     sample_times = 1,
     bleed_times = c(1, 3, 8, 15, 30, 45, 60),
     assay_error = 0.2,
     sm_span = 0.2)         
     
     
     sim_rwd$simulated_dataset_long$type <- "simulated"
     sim_rwd2 <- sim_rwd$simulated_dataset_long[, c("animal_sample", "time", "cort", "type")]
     rwde2 <- rwde[, c("id", "lat_sec", "cort")]
     rwde2$lat_sec <- rwde2$lat_sec / 60
     rwde2$type <- "red-winged blackbird"
     colnames(rwde2) <- c("animal_sample", "time", "cort", "type")
     
     comp_sim <- rbind(rwde2, sim_rwd2)
     
     p1 <- ggplot(comp_sim, mapping = aes(x = time, y = cort, by = animal_sample, color = type)) +
       geom_line(alpha = 0.7, size = 0.7) +
       theme_classic() +
       coord_cartesian(xlim = c(0, 60), ylim = c(0, 125)) +
       xlab("Time (minutes)") + ylab("Corticosterone (ng/\U00B5l)") +
       scale_color_manual(values = c("slateblue", "orange")) +
       guides(color = FALSE) +
       theme(axis.title = element_text(size = 14)) +
       annotate(geom = "text", x = -Inf, y = Inf, hjust = -.5, vjust = 1.5, label = "A")
     
     p2 <- ggplot(comp_sim, mapping = aes(x = time, y = cort, color = type, fill = type)) +
       geom_smooth() +
       theme_classic() + 
       coord_cartesian(xlim = c(0, 60), ylim = c(0, 125)) +
       xlab("Time (minutes)") + ylab("Corticosterone (ng/\U00B5l)") +
       scale_color_manual(values = c("slateblue", "orange")) +
       scale_fill_manual(values = c("slateblue", "orange")) +
       theme(legend.position = c(0.7, 0.15), axis.title = element_text(size = 14)) +
       guides(color = guide_legend(title = ""), fill = guide_legend(title = "")) +
       annotate(geom = "text", x = -Inf, y = Inf, hjust = -.5, vjust = 1.5, label = "B")

      ggpubr::ggarrange(p1, p2, nrow = 1) 
```

### *Accurately measuring a single glucocorticoid trait*

Single time point measures of glucocorticoids are often interpreted as representing meaningful variation between individuals. For example, variation in the level of glucocorticoids after 30 minutes of standardized restraint is typically interpreted as variation in the magnitude of the stress response [@taff2019]. However, this interpretation rests on assumptions that are rarely explicitly tested with empirical data. For example, the time chosen to take a stress-induced sample is often assumed to be either at the species peak or during a plateau period after the species peak. In some early studies, great care was taken to determine an average population level peak time [CITE], but many studies adopt the widely used 'standard' time of 30 minutes post capture without extensive validation. While there is a general assumption that sampling later than the peak is acceptable (and perhaps preferable) because animals will be sampled during a relatively stable high plateau, there is little empirical data to evaluate this assertion or to determine how much under or overshooting the species peak timing might influence inferences. Furthermore, even when the average peak timing is well established, differences in the amount of between-individual variation in the time to reach the peak or in peak values are common across species and even in different life history stages within species [CITE]. The combinations of these patterns of variation could have major consequences on the accuracy of single point estimates taken at 30 minutes, but these questions cannot be addressed directly with empirical datasets where the true underlying values of each individual are unknown.

Here, I simulate a simple scenario exploring the consequences of variation in each of these parameters on the accuracy of estimating between individual differences in maximally expressed glucocorticoids during an acute response. For purposes of this illustration, I consider a single study design in which animals are sampled at 30 minutes. Using this design as a starting point, I systematically vary i) the timing of the population average peak (15, 30, or 45 minutes), ii) the amount of variation in maximum glucocorticoid levels reached, iii) and the amount of variation in the number of minutes taken to reach peak levels. All other variables in the simulation are constrained to be invariant between individuals in the population (e.g., all individuals have identical baseline glucocorticoids in this case), though I consider cases in which multiple aspects of the rapid response are correlated with each other in the next section. I included moderate within-individual variability and a small amount of assay error across all iterations. For each combination of parameters, I simulated 200 animals and estimated the R^2^ value from a regression of the observed estimates of glucocorticoid levels at 30 minutes to the true known values. This simulation is likely a best case scenario because it eliminates many sources of variation or noise that would be present in real data, but it illustrates the effect of variation in these three key parameters even when the exact same sampling design is employed.

```{r max-sim, echo = FALSE, warning = FALSE, message = FALSE, fig.pos = "!h", fig.align = "center", fig.width = 8, fig.height = 3, fig.cap = "Results of simulation runs with different amounts of between-individual variation in the time to reach maximum glucocorticoid levels and in the maximum level reached. Simulations are run with samples taken at 30 minutes on populations with an average peak time of 15 minutes (left), 30 minutes (center), or 45 minutes (right). Each grid cell is the R$^2$ value from the regression of observed glucocorticoids at 30 minutes to true maximum levels in a simulation of 200 individuals."}
# set.seed(901)
# grid.size <- 15
# 
# max_sd <- seq(0.01, 0.26, length.out = grid.size)
# time_sd <- seq(1, 20, length.out = grid.size)
# #plateau <- c(2, 20)
# speeds <- c(15, 30, 45)
# 
# storer <- data.frame(max_sd = rep(rep(max_sd, grid.size), 3),
#                      time_sd = rep(rep(time_sd, each = grid.size), 3),
#                      rsq = rep(rep(NA, grid.size*grid.size), 3),
#                      slp = rep(rep(NA, grid.size*grid.size), 3),
#                      #plateau = rep(c("Short plateau", "Long plateau"), each = 300),
#                      speeds = rep(c("Mean max 15m", "Mean max 30m", "Mean max 45m"), each = grid.size*grid.size))
# 
# counter <- 0
# 
# #for(u in 1:length(plateau)){
#   for(k in 1:length(speeds)){
#     for(i in 1:length(time_sd)){
#         for(j in 1:length(max_sd)){
#           dm <- cort_sim2(data = cort_sim1(n = 200, base_mu = 0, base_sd = 0, slope_sd = 0, slope_mu = 5, fastpct_mu = 0.4, fastpct_sd = 0, maxtime_sd = 0, return_sd = 0,
#                                          speed_mu = speeds[k], 
#                                          speed_sd = time_sd[i],
#                                          max_mu = log(45),
#                                          max_sd = max_sd[j],
#                                          maxtime_mu = 10,
#                                          return_mu = speeds[k] + 60
#                                          ),
#                         bleed_times = c(2, 30),
#                         sample_times = 1)
#                         #base_error = 0, speed_error = 0, max_error = 0, maxtime_error = 0, return_error = 0, slope_error = 0, fastpct_error = 0)
#         
#           dm2 <- data.frame(max30 = subset(dm$simulated_dataset_long$cort, dm$simulated_dataset_long$time == 30),
#                           max_true = dm$true_values$max)
#           m <- lm(max_true ~ max30, data = dm2)
#           rs <- summary(m)$r.squared
#           
#           storer[counter + j, 3] <- rs
#           storer[counter + j, 4] <- coef(m)[2]
#         }
#       counter <- counter + grid.size
#       print(paste(i, "of", length(time_sd), sep = " "))
#     }
#     print(paste(k, "of", length(speeds)))
#   }
# #  print(paste(u, "of", length(plateau)))
# #}  

#saveRDS(storer, here::here("5_other_outputs/max_sim.rds"))
storer <-readRDS(here::here("5_other_outputs/max_sim.rds"))

# Making bins for r squared values
  storer$rsq2 <- cut(storer$rsq, breaks = seq(0, 1, 0.2))
  new_bins <- data.frame(rsq2 = levels(storer$rsq2),
                         rsq3 = c("0.0 - 0.2", "0.2 - 0.4", "0.4 - 0.6", "0.6 - 0.8", "0.8 - 1.0"))
  storer <- plyr::join(storer, new_bins, "rsq2")

# Putting max sd onto interpretable scale
  storer$max_sd2 <- (exp(storer$max_sd + rep(log(45), nrow(storer))) - exp(rep(log(45), nrow(storer)) - storer$max_sd)) / 2 
  
  

  
ggplot(data = storer, mapping = aes(x = time_sd, y = max_sd2, fill = rsq3)) +
  geom_tile() +
  scale_fill_viridis(option = "plasma", discrete = TRUE) +
  theme_bw() +
  theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank()) +
  ylab("Variation in max (SD ng/\U00B5l)") +
  xlab("Variation in time to reach max (SD minutes)") +
  facet_wrap(~ speeds, nrow = 1) +
  #facet_grid(rows = vars(plateau), cols = vars(speeds)) +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 12)) +
  guides(fill = guide_legend(reverse = TRUE)) +
  labs(fill = expression(paste("R"^{2})))

```

Results of this simulation are summarized in figure \@ref(fig:max-sim). The amount of between-individual variation in the maximum glucocorticoid value has a profound effect on the ability to detect true maximal levels with samples taken at 30 minutes. In one sense, this result is unsurprising because it is intuitive that large differences would be easier to detect, but there are important consequences of this fact for interpreting studies that seek to link between-individual variation in the magnitude of the stress response with other traits. For example, the magnitude of the acute stress response often varies substantially across life history stages [CITE]. Even if study designs are identical and maximum glucocorticoids are associated with performance, it will be easier to detect those patterns during life history stages with greater variation (see section on detecting fitness associations below). There is a weaker, but still substantial impact of variation in the time taken to reach maximum values on the accuracy of estimates in this simulation. Greater variation in time reduces the accuracy of estimates of maximal values. Finally, the timing of sampling relative to the average population peak timing also influences accuracy. Measuring after the average peak time results in the most accurate estimates across a range of parameter values, while measuring before the average peak time produces the least accurate measures, particularly when there is also high variation in the time to reach maximum values between individuals. This simple example demonstrates clearly that the same experimental design will perform better or worse depending on the combination of glucocorticoid regulation parameters in the population being studied. 

### *Exploring covariance between response components*

In reality, fully characterizing the acute glucocorticoid response requires more than identifying just the maximum value reached. Individuals may differ in baseline levels, rate of initial increase, the speed of reaching the maximum level, time spent at maximum, and the speed of return to baseline. Moreover, each of these components of the endocrine response could be positively or negatively correlated with each other within and between individuals. In these cases, measurements taken at particular time points contain information about multiple aspects of the response and without additional information it may be difficult to know what trait is being measured. The fact that each of these traits might be important and that they might covary has been discussed in a general sense [CITE], but simulations are uniquely powerful for exploring under exactly what conditions time point measure of glucocorticoids can or cannot be used as indicators of these traits. 

```{r cor-ex1, echo = FALSE, fig.height = 2.8, fig.width = 7.3, fig.pos = "!ht", fig.align = "center", message = FALSE, warning = FALSE, fig.cap = "Simulated glucocorticoid responses in which the maximum value and response speed are positively correlated (A), uncorrelated (B), or negatively correlated (C). Orange curves show the full response for each individual. Blue points show the maximum value and time to reach maximum for each individual. Blue lines are simple linear regressions of speed and maximum value for each group. For clarity, only the first 40 individuals in each simulated dataset are plotted."}
# 
# set.seed(431)
# 
# spd_sd <- 12
# mx_sd <- 0.21
# 
# c_pos <- cort_sim2(data = cort_sim1(n = 100, cor_speed_max = -0.6, speed_mu = 35, speed_sd = spd_sd, base_sd = 0,
#                                     slope_mu = 8, slope_sd = 0.1, fastpct_sd = 0, max_sd = mx_sd, speed_min = 8),
#                      bleed_times = c(1, 5, 10, 15, 30), sample_times = 1)
# c_zer <- cort_sim2(data = cort_sim1(n = 100, cor_speed_max = 0, speed_mu = 35, speed_sd = spd_sd, base_sd = 0,
#                                     slope_mu = 8, slope_sd = 0.1, fastpct_sd = 0, max_sd = mx_sd, speed_min = 8),
#                      bleed_times = c(1, 5, 10, 15, 30), sample_times = 1)
# c_neg <- cort_sim2(data = cort_sim1(n = 100, cor_speed_max = 0.6, speed_mu = 35, speed_sd = spd_sd, base_sd = 0,
#                                     slope_mu = 8, slope_sd = 0.1, fastpct_sd = 0, max_sd = mx_sd, speed_min = 8),
#                     bleed_times = c(1, 5, 10, 15, 30), sample_times = 1)
# 
# c1 <- c_pos$timecourse_long
# c1$run <- "faster = higher"
# c2 <- c_zer$timecourse_long
# c2$run <- "uncorrelated"
# c3 <- c_neg$timecourse_long
# c3$run <- "faster = lower"
# 
# c_comb <- rbind(c1[1:(50 * 171), ], c2[1:(50 * 171), ], c3[1:(50 * 171), ])
# c_comb$as_run <- paste(c_comb$animal, c_comb$run, sep = "_")
# c_comb_tem <- c_comb[!duplicated(c_comb$as_run), ]
# 
# c_comb$run <- factor(c_comb$run, levels = c("faster = higher", "uncorrelated", "faster = lower"))
# 
# for(i in 1:nrow(c_comb_tem)){
#   sub <- subset(c_comb, c_comb$as_run == c_comb_tem$as_run[i])
#   maxc <- sub[which.max(sub$cort), ]
#   if(i == 1){max_vals <- maxc}
#   if(i > 1){max_vals <- rbind(max_vals, maxc)}
# }
# 
# # Add text with dataframe that has a/b/c
# 
# text_labs <- data.frame(time = rep(1, 3),
#                         cort = rep(77, 3),
#                         run = levels(c_comb$run),
#                         labs = c("A", "B", "C"),
#                         animal = rep(NA, 3))
# 
# text_labs$run <- factor(text_labs$run, levels = c("faster = higher", "uncorrelated", "faster = lower"))
# 
# #Bookdown wasn't rendering this figure properly so I've saved and loaded it here.
# pcor <- ggplot(data = c_comb, mapping = aes(x = time, y = cort)) +
#   geom_line(color = "orange", alpha = 0.5, mapping = aes(by = animal)) + theme_bw() +
#   facet_wrap(~ run) +
#   geom_smooth(data = max_vals, se = FALSE, color = "slateblue", alpha = 0.6, method = "lm") +
#   coord_cartesian(xlim = c(0, 80)) +
#   geom_point(data = max_vals, color = "slateblue", alpha = 0.6) +
#   theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
#   xlab("Time (minutes)") + ylab("Glucocorticoids (ng/\U00B5l)") +
#   theme(axis.title = element_text(size = 12)) +
#   geom_text(data = text_labs, mapping = aes(label = labs), size = 5)

#saveRDS(pcor, here::here("5_other_outputs/example_corr.rds"))

pcor <- readRDS(here::here("5_other_outputs/example_corr.rds"))
pcor
 
```

To illustrate this point, I explored the consequences of variation in the correlation between and relative amount of variation in just two aspects of the acute stress response: the maximum glucocorticoid level reached and the time required to reach the maximum level. For simplicity, I refer to the 'speed' of the response, but note that other aspects, such as the rate of initial increase, could also be considered as variation in the speed of response. When considering these two traits, a population of animals could plausibly display one of three patterns. Individuals that reach their maximum value faster might also reach higher values (figure \@ref(fig:cor-ex1)A; simulation correlation = -0.6). Alternatively, the speed and maximum values might vary independently (figure \@ref(fig:cor-ex1)B; correlation = 0). Finally, individuals that are faster might max out at lower glucocorticoid values (figure \@ref(fig:cor-ex1)C; correlation = 0.6). While many researchers in this field might have intuitions about which of these scenarios is most likely to prevail, there is very little empirical data available to actually determine which is most common. Moreover, regardless of the specifics for this particular correlation, the general pattern and considerations presented here will apply in similar ways to correlations between other aspects of the acute stress response.

Using these three simulated populations as a starting point, I asked how well glucocorticoid values measured at one timepoint reflected true trait values. For each population I set an average population level speed of 30 minutes with other values in the simulation set at their default value. For every time point from 0 to 35 minutes I fit two simple linear regressions of the measured value on the true speed and maximum value and extracted the R^2^ value from the model. I repeated this simulation for all populations 50 times with 100 individuals sampled from the population each time. Finally, I repeated the entire set of simulations with each combination of low and high between-individual variation in the speed or maximum values (variation in speed: low = 2 minute SD, high = 12 minute SD; variation in maximum: low = 1ng/$\mu$l SD, high = 10ng/$\mu$l SD).

```{r cor-ex2, echo = FALSE, fig.height = 6, fig.width = 7, fig.pos = "!ht", fig.align = "center", message = FALSE, warning = FALSE, fig.cap = "Relationship between single time point measures of glucocorticoids and the true value of either maximum level (solid lines) or the speed of the glucocorticoid response (dashed lines). Panels show results when the overall variation in maximum values and speed are both low (A), when one is low while the other is high (B and C), and when both are high (D). In each panel, three different simulation scenarios illustrate the patterns when speed and maximum value are positively correlated (purple), uncorrelated (teal), or negatively correlated (yellow). Faded lines show the results from each of 50 separate simulation runs and thick lines are the averages across all runs."}

# spd_sd <- c(2, 2, 12, 12)
# mx_sd <- c(0.02, 0.21, 0.02, 0.21)
# 
# for(u in 1:4){
#   for(k in 1:50){
#     # Create simulations that have positive, no, or negative correlatoins b/w speed and scope
#       c_pos <- cort_sim2(data = cort_sim1(n = 100, cor_speed_max = -0.6, speed_mu = 30, speed_sd = spd_sd[u], 
#                                           slope_mu = 8, max_sd = mx_sd[u], speed_min = 8), 
#                            bleed_times = c(1, 5, 10, 15, 30), sample_times = 1)
#       c_zer <- cort_sim2(data = cort_sim1(n = 100, cor_speed_max = 0, speed_mu = 30, speed_sd = spd_sd[u],
#                                           slope_mu = 8, max_sd = mx_sd[u], speed_min = 8), 
#                            bleed_times = c(1, 5, 10, 15, 30), sample_times = 1)
#       c_neg <- cort_sim2(data = cort_sim1(n = 100, cor_speed_max = 0.6, speed_mu = 30, speed_sd = spd_sd[u],
#                                           slope_mu = 8, max_sd = mx_sd[u], speed_min = 8),
#                           bleed_times = c(1, 5, 10, 15, 30), sample_times = 1)
#     
#     # Determine correlation between each timepoint measure and speed and max for each simulation and combine
#           times1 <- data.frame(time = unique(c_pos$timecourse_long$time),
#                         cor_spd = NA,
#                         cor_max = NA,
#                         run = "faster = higher")
#           for(i in 1:50){
#             dat <- subset(c_pos$timecourse_long, c_pos$timecourse_long$time == i)
#             dat <- plyr::join(dat, c_pos$true_values, "animal")
#             times1$cor_spd[i] <- cor(dat$cort, dat$speed) ^ 2
#             times1$cor_max[i] <- cor(dat$cort, dat$max) ^ 2
#             
#           
#           }
#           
#           times2 <- data.frame(time = unique(c_zer$timecourse_long$time),
#                               cor_spd = NA,
#                               cor_max = NA,
#                               run = "uncorrelated")
#           for(i in 1:50){
#             dat <- subset(c_zer$timecourse_long, c_zer$timecourse_long$time == i)
#             dat <- plyr::join(dat[, c("animal", "time", "cort")], c_zer$true_values, "animal")
#             times2$cor_spd[i] <- cor(dat$cort, dat$speed) ^ 2
#             times2$cor_max[i] <- cor(dat$cort, dat$max) ^ 2
#             ggplot(data = dat, mapping = aes(x = cort, y = speed)) + geom_smooth(method = "lm") + geom_point()
#             cor(dat$cort, dat$speed) ^2
#           }
#           
#           times3 <- data.frame(time = unique(c_neg$timecourse_long$time),
#                               cor_spd = NA,
#                               cor_max = NA,
#                               run = "faster = lower")
#           for(i in 1:50){
#             dat <- subset(c_neg$timecourse_long, c_neg$timecourse_long$time == i)
#             dat <- plyr::join(dat, c_neg$true_values, "animal")
#             times3$cor_spd[i] <- cor(dat$cort, dat$speed) ^ 2
#             times3$cor_max[i] <- cor(dat$cort, dat$max) ^ 2
#           }
#           
#           times <- rbind(times1, times2, times3)
#           times$spd_sd <- rep(spd_sd[u], nrow(times))
#           times$max_sd <- rep(mx_sd[u], nrow(times))
#           times$run_num <- paste(u, k, sep = "_")
#           
#           if(k == 1){if(u == 1){time_out <- times}}
#           if(k == 1){if(u > 1){time_out <- rbind(time_out, times)}}
#           if(k > 1){time_out <- rbind(time_out, times)}
#           
#           print(paste(k, "of 50 run", u, "of 4", sep = " "))
#     
#   }
#   
# }
# 
# time_out2 <- pivot_longer(time_out, cols = cor_spd:cor_max, names_to = "type", values_to = "correl")
# time_out2$run <- factor(time_out2$run, levels = c("faster = higher", "uncorrelated", "faster = lower"))
# 
# mx <- data.frame(max_sd = c(0.02, 0.21),
#                  max_sd2 = c("Low variation in max", "High variation in max"))
# sp <- data.frame(spd_sd = c(2, 12),
#                  spd_sd2 = c("Low variation in speed", "High variation in speed"))
# 
# time_out2 <- plyr::join(time_out2, mx, "max_sd")
# time_out2 <- plyr::join(time_out2, sp, "spd_sd")
# 
# time_out2$max_sd2 <- factor(time_out2$max_sd2, levels = c("Low variation in max", "High variation in max"))
# time_out2$spd_sd2 <- factor(time_out2$spd_sd2, levels = c("Low variation in speed", "High variation in speed"))
# 
# time_out2$type <- gsub("cor_max", "maximum", time_out2$type)
# time_out2$type <- gsub("cor_spd", "speed", time_out2$type)
# 
# to_lab <- data.frame(labs = c("A", "B", "C", "D"),
#                      run = rep("uncorrelated", 4),
#                      correl = rep(0.98, 4),
#                      type = rep(NA, 4),
#                      time = rep(0, 4),
#                      run_num = rep(NA, 4),
#                      max_sd = c(0.02, 0.02, 0.21, 0.21),
#                      spd_sd = c(2, 12, 2, 12),
#                      max_sd2 = c(rep("Low variation in max", 2), rep("High variation in max", 2)),
#                      spd_sd2 = rep(c("Low variation in speed", "High variation in speed"), 2))
# 
# to_lab$max_sd2 <- factor(to_lab$max_sd2, levels = c("Low variation in max", "High variation in max"))
# to_lab$spd_sd2 <- factor(to_lab$spd_sd2, levels = c("Low variation in speed", "High variation in speed"))
# 
# p4 <- ggplot(data = time_out2, mapping = aes(x = time, y = correl, color = run, linetype = type, fill = run)) +
#   geom_line(mapping = aes(by = run_num), alpha = 0.1) +
#   geom_smooth(alpha = 0.4, se = FALSE) +
#   scale_color_viridis(discrete = TRUE) +
#   scale_fill_viridis(discrete = TRUE) +
#   theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
#   coord_cartesian(xlim = c(0, 35), ylim = c(0, 1)) +
#   theme(axis.title = element_text(size = 13)) +
#   #geom_line(mapping = aes(y = cor_max), linetype = "dashed", size = 2) +
#   xlab("Time (minutes)") + ylab(expression(paste("R"^{2}, " measured vs. true trait"))) +
#   facet_grid(rows = vars(max_sd2), cols = vars(spd_sd2)) +
#   geom_text(data = to_lab, mapping = aes(label = labs), color = "black", size = 5) +
#   labs(linetype = "Trait", color = "Correlation") + guides(fill = FALSE)
#   
# 
# saveRDS(p4, here::here("5_other_outputs/example_corr2.rds"))


p4 <- readRDS(here::here("5_other_outputs/example_corr2.rds"))
p4 + theme(legend.position = "top")
```

The time that samples were taken at, relative amount of variation in speed and maximum, and degree of correlation between the speed and maximum all had substantial impacts on the ability to infer true trait values from single time point glucocorticoid measures (figure \@ref(fig:cor-ex2)). While these scenarios do not explore all possible parameter space, there are several clear conclusions that can be made. First, neither speed or maximum traits could be assessed accurately when between-individual variation in both traits was low (figure \@ref(fig:cor-ex2)A). This is potentially important for interpreting apparent differences in glucocorticoid fitness relationships because between-individual variation is known to differ across life history stages [CITE]. Second, accurately assessing variation in speed was much harder-if not impossible-with single measures. 

Only when speed varied between individuals with very low variation in maximum was it possible to accurately measure speed, but this situation may be rare in natural populations. When speed was tightly correlated with maximum (figure \@ref(fig:cor-ex2)D) it was sometimes possible to attain reasonable estimates of speed (figure \@ref(fig:cor-ex2)C-D), but when speed was not correlated with maximum single measures were not good indicators of variation in speed (figure \@ref(fig:cor-ex2)A, C-D). Finally, measuring variation in maximum values was much easier under many conditions (figure \@ref(fig:cor-ex2)C-D), but the accuracy of assessment of maximum values was also negative impacted by variation in speed and the degree of this impact differed depending on the correlation between the two traits (figure \@ref(fig:cor-ex2)). Beyond the specifics of this particular example, what these results demonstrate clearly is that understanding what aspect of the glucocorticoid response is being measured by any particular study design depends on extensive knowledge of the overall shape and amount of variation in different aspects of the acute stress response.

### *Detecting links between fitness and responses*

A common goal of recent studies is to establish whether variation in glucocorticoids is associated with fitness or some proxy for fitness [@schoenle2020]. While there has been a great deal of discussion about the extent to which these relationships might differ with life history characteristics or between breeding stages [CITE], there has been relatively little consideration of the way that methodological limitations might limit the ability to detect these relationships even when they exist. 


```{r fitness-ex, echo = FALSE, fig.height = 8, fig.width = 8, fig.pos = "!ht", fig.align = "center", message = FALSE, warning = FALSE, fig.cap = "Relationship between observed maximum glucocorticoid values and fitness for simulated populations that have low between-individual variation (blue) or high between-individual variation (red). Each point is the result of a separate simulation of 50 individuals using the settings described in the text. Filled circles are simulations in which observed glucocorticoid values at 30 minutes were significantly correlated with fitness and crosses are simulations in which the relationship was not significant. Panels illustrate conditions with low measurement error (A, C) versus high measurement error (B, D) and low within-individual variation (A, B) versus high within-individual variation (C, D). For each simulation, the correlation between true maximum glucocorticoids fitness is plotted on the y-axis and the correaltion with observed values is plotted on the x-axis."}
#draw figure ----
# n_sam <- 50
# fit_dat <- data.frame(f1b_true = rep(NA, n_sam), f1b_obs = rep(NA, n_sam), f1b_p = rep(NA, n_sam),
#                       f2b_true = rep(NA, n_sam), f2b_obs = rep(NA, n_sam), f2b_p = rep(NA, n_sam))
# 
# for(i in 1:n_sam){
#       f1 <- cort_sim2(data = cort_sim1(n = 50, max_mu = log(45), max_sd = 0.21, speed_mu = 30, speed_sd = 1), 
#                                 bleed_times = c(2, 30), sample_times = 1, assay_error = 0.1, max_error = 0.2,
#                     performance_contributions = c(0, 0, 5, 0, 0, 0, 0, 5))
#     f1b <- plyr::join(f1$simulated_dataset_long[, c("animal", "time", "cort")], f1$true_values, "animal")
#     f1b <- subset(f1b, f1b$time == 30)
#     fit_dat$f1b_true[i] <- cor(f1b$max, f1b$performance)
#     fit_dat$f1b_obs[i] <- cor(f1b$cort, f1b$performance)
#     fit_dat$f1b_p[i] <- coef(summary(lm(performance ~ cort, data = f1b)))[2, 4]
#     
#     
#     f2 <- cort_sim2(data = cort_sim1(n = 50, speed_mu = 30, max_mu = log(45), max_sd = 0.03, speed_sd = 1), 
#                                 bleed_times = c(2, 30), sample_times = 1,
#                     performance_contributions = c(0, 0, 5, 0, 0, 0, 0, 5), assay_error = 0.1, max_error = 0.2)
#     f2b <- plyr::join(f2$simulated_dataset_long[, c("animal", "time", "cort")], f2$true_values, "animal")
#     f2b <- subset(f2b, f2b$time == 30)
#     fit_dat$f2b_true[i] <- cor(f2b$max, f2b$performance)
#     fit_dat$f2b_obs[i] <- cor(f2b$cort, f2b$performance)
#     fit_dat$f2b_p[i] <- coef(summary(lm(performance ~ cort, data = f2b)))[2, 4]
#     print(paste(i, "of", n_sam, sep = " "))
# }
# 
# fd1 <- fit_dat[, 1:3]
# fd2 <- fit_dat[, 4:6]
# colnames(fd1) <- c("true", "obs", "p")
# colnames(fd2) <- c("true", "obs", "p")
# 
# fd1$dif <- fd1$obs - fd1$true
# fd2$dif <- fd2$obs - fd2$true
# 
# fd1$group <- "High"
# fd2$group <- "Low"
# 
# f3 <- rbind(fd1, fd2)
# 
# f3$group <- as.factor(f3$group)
# f3$shp <- NA
# 
# for(i in 1:nrow(f3)){
#   ifelse(f3$p[i] < 0.05, f3$shp[i] <- "A", f3$shp[i] <- "B")
# }
# f3a <- f3
# pa <- ggplot(data = f3a, mapping = aes(x = obs, y = true, colour = group, fill = group)) +
#   geom_point(alpha = 0.7, mapping = aes(shape = shp)) + 
#   #geom_smooth(method = "lm", alpha = 0.3) +
#   #geom_boxplot(mapping = aes(x = true, y = obs), orientation = "y", alpha = 0.3, outlier.shape = NA, width = 1) +
#   scale_color_manual(values = c("coral3", "slateblue")) +
#   scale_fill_manual(values = c("coral3", "slateblue")) +
#   theme_bw() +
#   theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
#   ggtitle("Low measurement error \nLow within-individual variation") +
#   xlab("") + ylab("True correlation") +
#   theme(legend.position = c(0.75, 0.15)) +
#   #guides(fill = guide_legend("Between-individual \nvariation"), color = guide_legend("Between-individual \nvariation")) +
#   guides(fill = FALSE, color = FALSE, shape = FALSE) +
#   scale_shape_manual(values = c(21, 3), guide = "none") +
#   #theme(legend.background = element_rect(fill = alpha("white", 0))) +
#   annotate(geom = "text", x = -Inf, y = Inf, hjust = -.5, vjust = 1.5, label = "A", size = 8) +
#   theme(axis.title = element_text(size = 13)) 
#   #annotate(geom = "text", x = -0.1, y = 0.52, label = "Low measurement error \nLow within-individual variation", hjust = 0)
# 
# pA <- ggExtra::ggMarginal(pa, groupFill = TRUE, groupColour = TRUE, type = "boxplot", margins = "both")
#  
# ## Low assay, high within
# 
# for(i in 1:n_sam){
#       f1 <- cort_sim2(data = cort_sim1(n = 50, max_mu = log(45), max_sd = 0.21, speed_mu = 30, speed_sd = 1), 
#                                 bleed_times = c(2, 30), sample_times = 1, assay_error = 0.4, max_error = 0.1,
#                     performance_contributions = c(0, 0, 5, 0, 0, 0, 0, 5))
#     f1b <- plyr::join(f1$simulated_dataset_long[, c("animal", "time", "cort")], f1$true_values, "animal")
#     f1b <- subset(f1b, f1b$time == 30)
#     fit_dat$f1b_true[i] <- cor(f1b$max, f1b$performance)
#     fit_dat$f1b_obs[i] <- cor(f1b$cort, f1b$performance)
#     fit_dat$f1b_p[i] <- coef(summary(lm(performance ~ cort, data = f1b)))[2, 4]
#     
#     
#     f2 <- cort_sim2(data = cort_sim1(n = 50, speed_mu = 30, max_mu = log(45), max_sd = 0.03, speed_sd = 1), 
#                                 bleed_times = c(2, 30), sample_times = 1,
#                     performance_contributions = c(0, 0, 5, 0, 0, 0, 0, 5), assay_error = 0.4, max_error = 0.1)
#     f2b <- plyr::join(f2$simulated_dataset_long[, c("animal", "time", "cort")], f2$true_values, "animal")
#     f2b <- subset(f2b, f2b$time == 30)
#     fit_dat$f2b_true[i] <- cor(f2b$max, f2b$performance)
#     fit_dat$f2b_obs[i] <- cor(f2b$cort, f2b$performance)
#     fit_dat$f2b_p[i] <- coef(summary(lm(performance ~ cort, data = f2b)))[2, 4]
#     print(paste(i, "of", n_sam, sep = " "))
# }
# 
# fd1 <- fit_dat[, 1:3]
# fd2 <- fit_dat[, 4:6]
# colnames(fd1) <- c("true", "obs", "p")
# colnames(fd2) <- c("true", "obs", "p")
# 
# fd1$dif <- fd1$obs - fd1$true
# fd2$dif <- fd2$obs - fd2$true
# 
# fd1$group <- "High"
# fd2$group <- "Low"
# 
# f3 <- rbind(fd1, fd2)
# 
# f3$group <- as.factor(f3$group)
# f3$shp <- NA
# for(i in 1:nrow(f3)){
#   ifelse(f3$p[i] < 0.05, f3$shp[i] <- "A", f3$shp[i] <- "B")
# }
# f3b <- f3
# pb <- ggplot(data = f3b, mapping = aes(x = obs, y = true, colour = group, fill = group)) +
#   geom_point(alpha = 0.7, mapping = aes(shape = shp)) + 
#   #geom_smooth(method = "lm", alpha = 0.3) +
#   #geom_boxplot(mapping = aes(x = true, y = obs), orientation = "y", alpha = 0.3, outlier.shape = NA, width = 1) +
#   scale_color_manual(values = c("coral3", "slateblue")) +
#   scale_fill_manual(values = c("coral3", "slateblue")) +
#   theme_bw() +
#   theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
#   ggtitle("High measurement error \nLow within-individual variation") +
#   xlab("") + ylab("") +
#   #theme(legend.position = c(0.82, 0.15)) +
#   #guides(fill = guide_legend("Between-individual \nvariation"), color = guide_legend("Between-individual \nvariation")) +
#   guides(fill = "none", color = "none") +
#   scale_shape_manual(values = c(21, 3), guide = "none") +
#   annotate(geom = "text", x = -Inf, y = Inf, hjust = -.5, vjust = 1.5, label = "B", size = 8) +
#   theme(axis.title = element_text(size = 13)) 
#   #annotate(geom = "text", x = 0.19, y = 0.51, label = "High measurement error \nLow within-individual variation", hjust = 0)
# 
# pB <- ggExtra::ggMarginal(pb, groupFill = TRUE, groupColour = TRUE, type = "boxplot", margins = "both") 
# 
# ## Low assay, high within
# 
# for(i in 1:n_sam){
#       f1 <- cort_sim2(data = cort_sim1(n = 50, max_mu = log(45), max_sd = 0.21, speed_mu = 30, speed_sd = 1), 
#                                 bleed_times = c(2, 30), sample_times = 1, assay_error = 0.1, max_error = 0.6,
#                     performance_contributions = c(0, 0, 5, 0, 0, 0, 0, 5))
#     f1b <- plyr::join(f1$simulated_dataset_long[, c("animal", "time", "cort")], f1$true_values, "animal")
#     f1b <- subset(f1b, f1b$time == 30)
#     fit_dat$f1b_true[i] <- cor(f1b$max, f1b$performance)
#     fit_dat$f1b_obs[i] <- cor(f1b$cort, f1b$performance)
#     fit_dat$f1b_p[i] <- coef(summary(lm(performance ~ cort, data = f1b)))[2, 4]
#     
#     
#     f2 <- cort_sim2(data = cort_sim1(n = 50, speed_mu = 30, max_mu = log(45), max_sd = 0.03, speed_sd = 1), 
#                                 bleed_times = c(2, 30), sample_times = 1,
#                     performance_contributions = c(0, 0, 5, 0, 0, 0, 0, 5), assay_error = 0.1, max_error = 0.6)
#     f2b <- plyr::join(f2$simulated_dataset_long[, c("animal", "time", "cort")], f2$true_values, "animal")
#     f2b <- subset(f2b, f2b$time == 30)
#     fit_dat$f2b_true[i] <- cor(f2b$max, f2b$performance)
#     fit_dat$f2b_obs[i] <- cor(f2b$cort, f2b$performance)
#     fit_dat$f2b_p[i] <- coef(summary(lm(performance ~ cort, data = f2b)))[2, 4]
#     print(paste(i, "of", n_sam, sep = " "))
# }
# 
# fd1 <- fit_dat[, 1:3]
# fd2 <- fit_dat[, 4:6]
# colnames(fd1) <- c("true", "obs", "p")
# colnames(fd2) <- c("true", "obs", "p")
# 
# fd1$dif <- fd1$obs - fd1$true
# fd2$dif <- fd2$obs - fd2$true
# 
# fd1$group <- "High"
# fd2$group <- "Low"
# 
# f3 <- rbind(fd1, fd2)
# 
# f3$group <- as.factor(f3$group)
# f3$shp <- NA
# for(i in 1:nrow(f3)){
#   ifelse(f3$p[i] < 0.05, f3$shp[i] <- "A", f3$shp[i] <- "B")
# }
# f3c <- f3
# pc <- ggplot(data = f3c, mapping = aes(x = obs, y = true, colour = group, fill = group)) +
#   geom_point(alpha = 0.7, mapping = aes(shape = shp)) + 
#   #geom_smooth(method = "lm", alpha = 0.3) +
#   #geom_boxplot(mapping = aes(x = true, y = obs), orientation = "y", alpha = 0.3, outlier.shape = NA, width = 1) +
#   scale_color_manual(values = c("coral3", "slateblue")) +
#   scale_fill_manual(values = c("coral3", "slateblue")) +
#   theme_bw() +
#   theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
#   ggtitle("Low measurement error \nHigh within-individual variation") +
#   xlab("Observed correlation") + ylab("True correlation") +
#   #theme(legend.position = c(0.82, 0.15)) +
#   #guides(fill = guide_legend("Between-individual \nvariation"), color = guide_legend("Between-individual \nvariation")) +
#   guides(fill = "none", color = "none") +
#   scale_shape_manual(values = c(21, 3), guide = "none") +
#   annotate(geom = "text", x = -Inf, y = Inf, hjust = -.5, vjust = 1.5, label = "C", size = 8) +
#   theme(axis.title = element_text(size = 13)) 
#   #annotate(geom = "text", x = 0.19, y = 0.51, label = "Low measurement error \nHigh within-individual variation", hjust = 0)
# 
# pC <- ggExtra::ggMarginal(pc, groupFill = TRUE, groupColour = TRUE, type = "boxplot", margins = "both")
# 
# ## high assay, high within
# 
# for(i in 1:n_sam){
#       f1 <- cort_sim2(data = cort_sim1(n = 50, max_mu = log(45), max_sd = 0.21, speed_mu = 30, speed_sd = 1), 
#                                 bleed_times = c(2, 30), sample_times = 1, assay_error = 0.3, max_error = 0.6,
#                     performance_contributions = c(0, 0, 5, 0, 0, 0, 0, 5))
#     f1b <- plyr::join(f1$simulated_dataset_long[, c("animal", "time", "cort")], f1$true_values, "animal")
#     f1b <- subset(f1b, f1b$time == 30)
#     fit_dat$f1b_true[i] <- cor(f1b$max, f1b$performance)
#     fit_dat$f1b_obs[i] <- cor(f1b$cort, f1b$performance)
#     fit_dat$f1b_p[i] <- coef(summary(lm(performance ~ cort, data = f1b)))[2, 4]
#     
#     
#     f2 <- cort_sim2(data = cort_sim1(n = 50, speed_mu = 30, max_mu = log(45), max_sd = 0.03, speed_sd = 1), 
#                                 bleed_times = c(2, 30), sample_times = 1,
#                     performance_contributions = c(0, 0, 5, 0, 0, 0, 0, 5), assay_error = 0.3, max_error = 0.6)
#     f2b <- plyr::join(f2$simulated_dataset_long[, c("animal", "time", "cort")], f2$true_values, "animal")
#     f2b <- subset(f2b, f2b$time == 30)
#     fit_dat$f2b_true[i] <- cor(f2b$max, f2b$performance)
#     fit_dat$f2b_obs[i] <- cor(f2b$cort, f2b$performance)
#     fit_dat$f2b_p[i] <- coef(summary(lm(performance ~ cort, data = f2b)))[2, 4]
#     print(paste(i, "of", n_sam, sep = " "))
# }
# 
# fd1 <- fit_dat[, 1:3]
# fd2 <- fit_dat[, 4:6]
# colnames(fd1) <- c("true", "obs", "p")
# colnames(fd2) <- c("true", "obs", "p")
# 
# fd1$dif <- fd1$obs - fd1$true
# fd2$dif <- fd2$obs - fd2$true
# 
# fd1$group <- "High"
# fd2$group <- "Low"
# 
# f3 <- rbind(fd1, fd2)
# 
# f3$group <- as.factor(f3$group)
# f3$shp <- NA
# for(i in 1:nrow(f3)){
#   ifelse(f3$p[i] < 0.05, f3$shp[i] <- "A", f3$shp[i] <- "B")
# }
# f3d <- f3
# pd <- ggplot(data = f3d, mapping = aes(x = obs, y = true, colour = group, fill = group)) +
#   geom_point(alpha = 0.7, mapping = aes(shape = shp)) + 
#   #geom_smooth(method = "lm", alpha = 0.3) +
#   #geom_boxplot(mapping = aes(x = true, y = obs), orientation = "y", alpha = 0.3, outlier.shape = NA, width = 1) +
#   scale_color_manual(values = c("coral3", "slateblue")) +
#   scale_fill_manual(values = c("coral3", "slateblue")) +
#   theme_bw() +
#   theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
#   ggtitle("High measurement error \nHigh within-individual variation") +
#   xlab("Observed correlation") + ylab("") +
#   #theme(legend.position = c(0.82, 0.15)) +
#   #guides(fill = guide_legend("Between-individual \nvariation"), color = guide_legend("Between-individual \nvariation")) +
#   guides(fill = "none", color = "none") +
#   scale_shape_manual(values = c(21, 3), guide = "none") +
#   annotate(geom = "text", x = -Inf, y = Inf, hjust = -.5, vjust = 1.5, label = "D", size = 8) +
#   theme(axis.title = element_text(size = 13)) 
#   #annotate(geom = "text", x = 0.19, y = 0.51, label = "High measurement error \nHigh within-individual variation", hjust = 0)
# 
# pD <- ggExtra::ggMarginal(pd, groupFill = TRUE, groupColour = TRUE, type = "boxplot", margins = "both")
# 
# pAD <- ggpubr::ggarrange(pA, pB, pC, pD, nrow = 2, ncol = 2)
# 
# saveRDS(pAD, here::here("5_other_outputs/fitness-ex.rds"))

# reload and print ----
pAD <- readRDS(here::here("5_other_outputs/fitness-ex.rds"))
pAD 

```

Here, I imagine a simple scenario in which the 'true' maximum glucocorticoid level during an acute response explains 80% of the variation in fitness (clearly this is unrealistically high, but it is chosen for illustration only). I next construct a study in which researchers measure 50 individuals using a typical stress-induced (30 minute) sampling protocol. For simplicity, I set the other parameters in the simulation at their default values. Keeping the study design constant, I ask whether the glucocorticoid-fitness relationship can be recovered for two hypothetical populations that have low or high between-individual variation in maximum glucocorticoid levels. For each of these two populations, I ask how the ability to detect glucocorticoid-fitness relationships changes with different amounts of within-individual variation in acute response expression and with differing amounts of measurement error. For each combination of parameters, I simulated 50 populations and fit a simple linear regression model with observed glucocorticoid levels at 30 minutes as a predictor of fitness to ask whether the true glucocorticoid-fitness relationship was recovered. 

Several patterns can be identified by examining the results of this simulation. First, the correlation between the true maximum glucorticoid value and fitness does not differ for populations simulated with high or low between-individual variation (figure \@ref(fig:fitness-ex) A-D). In all cases, however, the observed correlation is always lower than the true correlation and always lowest in the population with low between-individual variation. The ubquity of this pattern is a product of the simulation structure, because adding measurement error or within-individual variation effecively add noise to the true correlation. It is important to note that in the real world, it is unlikely that this pattern would be so universal, because unmeasured variables could influence both fitness and glucocorticoids. For example, if habitat quality directly alters fitness and glucocorticoids, the observed correlation could be stronger than the 'true' correlation. Thus, interpretation of these results should be made cautiosly in light of the simplicity of the simulation compared to real world conditions.

Nevertheless, general patterns illustrated by the simulation are likely to pertain across a wide range of conditions. In this case, it is easiest to detect significant glucocorticoid-fitness relationships when both measurement error and within-individual variation are low (figure \@ref(fig:fitness-ex) A). It becomes harder to detect these true relationships when either measurement error (figure \@ref(fig:fitness-ex) B) or within-individual variation (figure \@ref(fig:fitness-ex) C) are high, but even in these more challenging situations the relationship can be detected the majority of the time if between-individual variation in maximum levels is high. When both measurement error and within-individual variation are high, it is nearly impossible to detect glucocorticoid-fitness relationships with low-between individual variation, but in populations with high between-individual variation the relationship is still detected in about half of the simulations. 

The fact that low between-individual variation in maximum glucocorticoids makes it harder to detect true glucocorticoid-fitness relationships across a wide range of conditions has important consequences for interpreting empirical results. 

### *Designing optimal sampling strategies*

One of the major benefits of simulating glucocorticoid response curves will be the ability to design optimal sampling strategies before data are collected. A simulation can be constrained to match any real world limitations (e.g., maximum number of samples possible per individual) and then explored to determine how to best allocate sampling resources. The specifics of this task will vary considerably with the study system and question being addressed, but here I illustrate one possible application. Consider an experiment in which the acute glucocorticoid response of a treatment group and control group are compared after some experimental manipulation. The details of the manipulation are unimportant here, but suppose that the prediction is that this manipulation should result in a difference in the speed of the corticosterone response between our two groups, such that the treatment group will reach it's maximum glucocorticoid value faster than the control group (figure \@ref(fig:prediction-ex)). 

For constraints, we can only sample a maximum of 20 individuals per group, we can only sample each individual once post-treatment, and during that single sampling event we can take a blood sample at a maximum of two different time points, resulting in a total of 40 data points per treatment group. Given these constraints, we can design a simulation to ask how well several different sampling schemes will perform in estimating the shape of the response curve for each group. I compare three different sampling designs: i) a study in which every animal is sampled at 1 minute and at 30 minutes, ii) a study in which two sampling times between 1 and 60 minutes are randomly chosen for every animal, iii) a study in which sampling times are randomly chosen for each animal, but weighted more heavily around 30 minutes, which is the expected average maximum glucocorticoid time. In the random sampling schemes, I constrain the randomization so that two samples from the same animal must be taken at least 5 minutes apart. To evaluate the performance of these sampling schemes, I simulated each one 50 times and fit a generalized additive model for each simulation with glucocorticoid level as the response and a treatment by smoothed time interaction as a predictor. Using the fit models, I asked how well each scheme estimated the time of maximum glucocorticoid and also how well the entire shape of the glucocorticoid response between 0 and 60 minutes was estimated.



```{r prediction-ex, echo = FALSE, fig.height = 8, fig.width = 8, fig.pos = "!ht", fig.align = "center", message = FALSE, warning = FALSE, fig.cap = "caption"}

#plot(1,1)

```

```{r treatment-ex, echo = FALSE, fig.height = 8, fig.width = 8, fig.pos = "!ht", fig.align = "center", message = FALSE, warning = FALSE, fig.cap = "caption"}

```


This simulation is particular to the specific scenario, but a similar scenario could be designed for any number of studies and any number of predictions about how the speed, scope, or other attributes of the glucocorticoid response are expected to change with a treatment. Clearly, when estimating the timing of peak glucocorticoids, a simple baseline plus induced sampling scheme is sub optimal, but this scheme may be perform well in other situations where the maximum value is the target and there is relatively little variation in response time. Creating simulations like this before studies are conducted has the potential increase the efficient use of researches time and funds, but also forces researches to think explicitly about quantitative predictions ahead of time. These simulations could be included as part of a study pre-registration, grant application, or registered report to demonstrate exactly what data collection and analysis approaches are planned and to justify those decisions. 



**Still working on thiis section. Will have two treatment groups with different response shapes and evaluate how well different sampling schemes recover those shapes.**

### Repeatability?    

The other example I had thought about including was something showing the repeatability functions and how repeatability of different measures might differ, but I'm leaning towards not including this since there is already a lot here.

## DISCUSSION 



More sophisticated simulations that incorporate mechanistic processes or other molecules or components of stress response system. 

Empirical data is so limited and hard to collect, that it makes sense to proceed with simulations to guide and focus empirical work and to determine whether empirical study designs actually have the ability in principle to support hypotheses of interest given reasonable effect sizes. 

More focus on measuring characteristics of the response other than just base/stress for all individuals. Group comparisons with treatments could look at shape changes.

Based on the brief scenarios developed above: 

Goal is for this to be a pretty short section highlighting some main insights from above examples and other ways simulations could be used.

## ACKNOWLEDGEMENTS

I would like to thank John Wingfield for discussions about the ideas presented in this project and for providing an insightful overview of the history of study design in field based studies of acute stress responses. I also thank members of the Vitousek Lab for feedback and discussion on early versions of this project. 

## REFERENCES

